I"Ê#<!-- Style for Publications Page -->
<style>
	table {
		width:100%;
		background: none;
	}
	td.paper_text {
		/* padding-top: 1rem; */
		padding-bottom: 4rem;
		width: 70%;
	}
	p.summary {
		margin-top: 0.5rem;
		margin-bottom: 0rem;
	}
	.award {
		color: deeppink;
	}
	img.icon {
		padding-top: 0.3rem;
		border-radius: 10px;
		width: 100%;
	}
	@media screen and (max-width: 1200px) {
		td.paper_text {
			width: 70%;
		}
	}
</style>

<p></p>

<div>
  <table>
	<tbody>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/NRIQA-Classifier-SaliencyMap.png" onmouseover="this.src='../assets/imgs/NRIQA-Classifier-QualityMap.png';" onmouseout="this.src='../assets/imgs/NRIQA-Classifier-SaliencyMap.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Saliency-Maps-NR-IQA-Classification-Models" style="font-size: 1.15em; color:#0073e6; font-weight:600">Similarities between local-patch quality maps of NR IQA algorithms and saliency maps of computer vision classification models.</a>
				</strong>
				<br />
				<p></p>
				<ul>
					<li>
						Achieved an understanding of similarities in the perception of images by humans and classification models. NR-IQA models, trained on human judgements/perception regarding quality, help to understand the perception of humans. <b>Local-patch quality maps</b> provide the key areas focused on while rating an image.
					</li>
					<li>
						Using <b>PaQ-2-PiQ</b> model to create local-patch quality maps for images. <b>ResNet18</b> model is trained on images rated as good-quality images by PaQ-2-PiQ and saliency maps are generated using Grad-CAM.
					</li>
					<li>
						Compared the variation in local-patch quality maps and saliency maps by natural scene <b>distortions</b> like brightness, contrast, jpeg-compression, motion-blur, zoom-blur etc. 
					</li>
				</ul>
			</td>
    	</tr>
    	<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/Autonomous-Navigation-Segmentation.png" onmouseover="this.src='../assets/imgs/Autonomous-Navigation-LaneDetection.png';" onmouseout="this.src='../assets/imgs/Autonomous-Navigation-Segmentation.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Autonomous-Driving" style="font-size: 1.15em; color:#0073e6; font-weight:600">Reinforcement Learning for Autonomous Navigation</a>
				</strong>
				<br />
				Guide: <a href="https://people.iith.ac.in/sumohana/" style="color:black;">Dr. Sumohana S. Channappayya</a>
				<p></p>
				<ul>
					<li>
						Applied reinforcement learning for <b>autonomous navigation</b> of cars with two objectives. One making sure the car is in the lane and the speed of the car is under speed limit.
					</li>
					<li>
						Agent can regulate speed and steering angle of car and is trained using <b>Deep-Q-Learning</b> and reward functions are designed from visual input from cameras using Segmentation and Lane Detection models.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/Modulation-Classification.png" onmouseover="this.src='../assets/imgs/Modulation-Classification.png';" onmouseout="this.src='../assets/imgs/Modulation-Classification.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Modulation-Classification" style="font-size: 1.15em; color:#0073e6; font-weight:600">AutoML Models for Wireless Signals Classification and their effectiveness against Adversarial Attacks</a>
				</strong>
				<br />
				Guide: <a href="https://people.iith.ac.in/asaidhiraj/" style="color:black;">Dr. SaiDhiraj Amuru</a>
				<p></p>
				<ul>
					<li>
						Created and explored performance of <b>AutoML</b> models on classification of wireless signals.
					</li>
					<li>
						Achieved an understanding in the <b>effectiveness</b> of AutoML models against transfer based white-box attacks to explain adversarial transferability of these attacks on AutoML models.
					</li>
					<li>
						Established a comparison the <b>performance</b> of AutoML models with state-of-the-art models in terms of classification, vulnerability and transferability.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/Video-Classification.png" onmouseover="this.src='../assets/imgs/Video-Classification.png';" onmouseout="this.src='../assets/imgs/Video-Classification.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Video-Classification" style="font-size: 1.15em; color:#0073e6; font-weight:600">Natural and Adversarial Corruptions on Video Classification</a>
				</strong>
				<br />
				Guide: <a href="https://people.iith.ac.in/sumohana/" style="color:black;">Dr. Sumohana S. Channappayya</a>
				<p></p>
				<ul>
					<li>
						Used CNN-RNN architecture for classifying videos.
					</li>
					<li>
						Designed various natural and adversarial single frame corruptions and understanding their impacts on classification.
					</li>
					<li>
						Designed a <b>reduced frame-level adversarial attack</b> to fool the video classification model.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/BHTvsBC.png" onmouseover="this.src='../assets/imgs/BHTvsBC.png';" onmouseout="this.src='../assets/imgs/BHTvsBC.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Hypothesis-Testing-vs-Binary-Classification" style="font-size: 1.15em; color:#0073e6; font-weight:600">Binary Hypothesis Testing vs Machine Learning Binary Classification</a>
				</strong>
				<br />
				Guide: <a href="https://iith.ac.in/math/sameen/" style="color:black;">Dr. Sameen Naqvi</a>
				<p></p>
				<ul>
					<li>
						Worked on differences between Hypothesis Testing and Binary Classification from <b>data and decision rule perspectives</b> using Banknote Authentication dataset.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/SD.png" onmouseover="this.src='../assets/imgs/SD.png';" onmouseout="this.src='../assets/imgs/SD.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Image-Processing/tree/master/Social-Distancing-Detection" style="font-size: 1.15em; color:#0073e6; font-weight:600">Social Distancing Detection</a>
				</strong>
				<p></p>
				<ul>
					<li>
						Developed a system for detecting violation of Social Distancing using YOLOv3-SPP Model with COCO Dataset weights for object detection and designed a violation detector from bounding boxes and their location in the image.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/HMM.png" onmouseover="this.src='../assets/imgs/HMM.png';" onmouseout="this.src='../assets/imgs/HMM.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/IIT-Hyderabad-Semester-Courses/blob/master/EE5602/HW0/HW0.ipynb" style="font-size: 1.15em; color:#0073e6; font-weight:600">Hidden Markov Models</a>
				</strong>
				<br />
				Guide: <a href="https://people.iith.ac.in/sumohana/" style="color:black;">Dr. Sumohana S. Channappayya</a>
				<p></p>
				<ul>
					<li>
						Implemented a basic two-class classifier using HMMs which classifies depending on likelihood. HMMs are constructed on MFCCs from raw speech samples and forward backward algorithm is used to learn the parameters of a HMMs.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/Music-Generation.png" onmouseover="this.src='../assets/imgs/Music-Generation.png';" onmouseout="this.src='../assets/imgs/Music-Generation.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Speech-and-Audio-Processing/tree/master/Music%20Generation" style="font-size: 1.15em; color:#0073e6; font-weight:600">Music Generation</a>
				</strong>
				<p></p>
				<ul>
					<li>
						Developed a automatic music generation for Mendelssohn Piano collection. Generating music using two different techniques one with simple WaveNet  architecture which has dilated convolutional layers and another a sequential model using LSTM units.
					</li>
				</ul>
			</td>
    	</tr>
		<tr>
			<td>
	  			<img class="icon" src="../assets/imgs/Transliteration.png" onmouseover="this.src='../assets/imgs/Transliteration.png';" onmouseout="this.src='../assets/imgs/Transliteration.png';" />
			</td>
      		<td class="paper_text">
				<strong>
					<a href="https://github.com/dks2000dks/Natural-Language-Processing/tree/master/Transliteration/English-Hindi" style="font-size: 1.15em; color:#0073e6; font-weight:600">Transliteration</a>
				</strong>
				<p></p>
				<ul>
					<li>
						Developed a text-based transliteration from Hindi to English. A Encoder-Decoder architecture consisting of RNN units is used for Sequence-to-Sequence modelling for Hindi-English corpus.
					</li>
				</ul>
			</td>
    	</tr>
	</tbody>
</table>
</div>
:ET